{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.12","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"# Imports","metadata":{}},{"cell_type":"code","source":"# general purpose\nimport numpy as np\nimport pandas as pd\nfrom pathlib import Path\nimport matplotlib.pyplot as plt\nimport seaborn as sns\nimport heapq\nfrom tqdm.autonotebook import tqdm\nfrom scipy import stats\nimport cv2\nfrom collections import Counter\nimport warnings\n\n# metrics and model selection\nfrom sklearn.model_selection import StratifiedKFold\nfrom sklearn.metrics import mean_absolute_error\n\n# deep learning - general\nimport torch\nimport torch.nn as nn\nimport torch.nn.functional as F\nfrom torch.utils.data import Dataset, DataLoader, Subset\nfrom torch.optim import SGD, AdamW\nfrom torch.optim.lr_scheduler import StepLR\n\n# deep learning - vision utils & pretrained models\nfrom torchvision.io import read_image, ImageReadMode\nfrom torchvision.transforms.v2 import (\n    RandomHorizontalFlip, TrivialAugmentWide, \n    Compose, Resize, ConvertDtype\n)\nfrom torchvision.transforms.functional import to_pil_image\nfrom torchvision.models import (\n    EfficientNet_V2_M_Weights, efficientnet_v2_m,\n    ResNet50_Weights, resnet50\n)\n\n\n# customary cuda detection\ndevice = \"cuda\" if torch.cuda.is_available else \"cpu\"\ndevice","metadata":{"execution":{"iopub.status.busy":"2023-09-12T03:52:31.804719Z","iopub.execute_input":"2023-09-12T03:52:31.805189Z","iopub.status.idle":"2023-09-12T03:52:38.722989Z","shell.execute_reply.started":"2023-09-12T03:52:31.805157Z","shell.execute_reply":"2023-09-12T03:52:38.721938Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Utils","metadata":{}},{"cell_type":"code","source":"ROOT_PATH = Path(\"../input/how-much-would-you-pay-for-a-fake-cat/\")\nIMG_PATH = ROOT_PATH / \"images\" / \"images\"","metadata":{"execution":{"iopub.status.busy":"2023-09-12T03:52:38.725054Z","iopub.execute_input":"2023-09-12T03:52:38.726345Z","iopub.status.idle":"2023-09-12T03:52:38.731765Z","shell.execute_reply.started":"2023-09-12T03:52:38.726305Z","shell.execute_reply":"2023-09-12T03:52:38.730234Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# faster than via numpy's argpartition\ndef topk(arraylike, k=10):\n    return np.sort(heapq.nlargest(k,arraylike))","metadata":{"execution":{"iopub.status.busy":"2023-09-12T03:52:38.733348Z","iopub.execute_input":"2023-09-12T03:52:38.734568Z","iopub.status.idle":"2023-09-12T03:52:38.745337Z","shell.execute_reply.started":"2023-09-12T03:52:38.734530Z","shell.execute_reply":"2023-09-12T03:52:38.744189Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# display images from tensors\ndef show(imgs, size=None):\n    if not isinstance(imgs, list):\n        imgs = [imgs]\n    fix, axs = plt.subplots(ncols=len(imgs), squeeze=False, figsize=size)\n    for i, img in enumerate(imgs):\n        img = img.detach()\n        img = to_pil_image(img)\n        axs[0, i].imshow(np.asarray(img))\n        axs[0, i].set(xticklabels=[], yticklabels=[], xticks=[], yticks=[])","metadata":{"execution":{"iopub.status.busy":"2023-09-12T03:52:38.748771Z","iopub.execute_input":"2023-09-12T03:52:38.749446Z","iopub.status.idle":"2023-09-12T03:52:38.760084Z","shell.execute_reply.started":"2023-09-12T03:52:38.749408Z","shell.execute_reply":"2023-09-12T03:52:38.758790Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# read images - possibly all of them\ndef read_img(img_id):\n    img_path = IMG_PATH / (img_id + \".png\")\n    return read_image(str(img_path),mode=ImageReadMode.RGB)\n    \ndef read_all_imgs(img_ids, out_sz=(480,480)):\n    preprocess = Compose([\n            Resize(out_sz, antialias=True),\n            ConvertDtype(torch.float)\n    ])\n    return [preprocess(read_img(img_id)) for img_id in tqdm(img_ids)]","metadata":{"execution":{"iopub.status.busy":"2023-09-12T03:52:38.762044Z","iopub.execute_input":"2023-09-12T03:52:38.762551Z","iopub.status.idle":"2023-09-12T03:52:38.771422Z","shell.execute_reply.started":"2023-09-12T03:52:38.762511Z","shell.execute_reply":"2023-09-12T03:52:38.770331Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# training, evaluation and prediction utility functions\ndef train_one_epoch(model, optimizer, criterion, train_dataloader, device, print_frequency=None, scheduler=None):\n    model.train()\n    for idx, (imgs, targets) in enumerate(train_dataloader):\n        optimizer.zero_grad()\n        \n        imgs, targets = imgs.to(device), targets.to(device)\n        preds = model(imgs)\n        \n        # fix (n_pred, 1)-shaped predictions\n        if len(preds.shape)>1:\n            preds = preds.squeeze(-1)\n        \n        loss = criterion(targets, preds)\n        \n        if print_frequency is not None and (idx+1)%print_frequency == 0:\n            print(f\"Loss at iter {idx+1: >5}: {loss.cpu().detach().item(): .4f}\")\n        loss.backward()\n        \n        optimizer.step()\n        \n        if scheduler is not None:\n            scheduler.step()\n            \ndef evaluate(model, test_dataloader, device, clip=False):\n    model.eval()\n    \n    residuals = torch.empty((len(test_dataloader)), device=device)\n    preds = torch.empty((len(test_dataloader)), device=device)\n    with torch.no_grad():\n        for idx, (img, target) in enumerate(test_dataloader):\n            output = model(img.to(device)).squeeze()\n            preds[idx] = output\n            residuals[idx] = preds[idx] - target.to(device)\n        \n        # MAE\n        mae = residuals.abs().mean(0).cpu().detach().item()\n        preds = preds.cpu().detach()\n    \n    return mae, preds           \n\ndef predict(model, test_dataloader, device, use_tqdm=True):\n    model.eval()\n    preds = torch.empty((len(test_dataloader)), device=device)\n    with torch.no_grad():\n        iterator = enumerate(test_dl)\n        if use_tqdm:\n            iterator = tqdm(iterator, total=len(test_dl))\n        for idx, img in iterator:\n            preds[idx] = model(img.to(device)).squeeze()\n    return preds.cpu().detach().numpy()","metadata":{"execution":{"iopub.status.busy":"2023-09-12T03:52:38.772931Z","iopub.execute_input":"2023-09-12T03:52:38.774067Z","iopub.status.idle":"2023-09-12T03:52:38.791529Z","shell.execute_reply.started":"2023-09-12T03:52:38.774030Z","shell.execute_reply":"2023-09-12T03:52:38.790327Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# submitting\ndef submit(preds, out_name):\n    submission = test_df[[\"id\"]].copy()\n    submission[\"price\"] = preds\n    submission.to_csv(out_name+\".csv\", index=False)","metadata":{"execution":{"iopub.status.busy":"2023-09-12T03:52:38.793118Z","iopub.execute_input":"2023-09-12T03:52:38.794234Z","iopub.status.idle":"2023-09-12T03:52:38.806485Z","shell.execute_reply.started":"2023-09-12T03:52:38.794195Z","shell.execute_reply":"2023-09-12T03:52:38.805324Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Loading data","metadata":{}},{"cell_type":"code","source":"train_df = pd.read_csv(ROOT_PATH / \"train.csv\")\ntest_df = pd.read_csv(ROOT_PATH / \"test.csv\")","metadata":{"execution":{"iopub.status.busy":"2023-09-12T03:52:38.807995Z","iopub.execute_input":"2023-09-12T03:52:38.809200Z","iopub.status.idle":"2023-09-12T03:52:38.849878Z","shell.execute_reply.started":"2023-09-12T03:52:38.809162Z","shell.execute_reply":"2023-09-12T03:52:38.848691Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Quick glance at data","metadata":{}},{"cell_type":"code","source":"# peek at training data\ntrain_df.head()","metadata":{"execution":{"iopub.status.busy":"2023-09-12T03:52:38.851367Z","iopub.execute_input":"2023-09-12T03:52:38.852363Z","iopub.status.idle":"2023-09-12T03:52:38.876735Z","shell.execute_reply.started":"2023-09-12T03:52:38.852325Z","shell.execute_reply":"2023-09-12T03:52:38.875336Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"For each observation we have:\n\n* **id**: the image id\n* **price**: how much ETH it costs. This is the target variable.\n* **speed**: the cooldown time for the NFT image.\n* **image**: the (broken @ Kaggle FS) path to the image. \n\nNote that [as specified in the competition](https://www.kaggle.com/competitions/how-much-would-you-pay-for-a-fake-cat/data), the image path always has the \"image/\"+ id + \".png\" format, hence the image path is a redundant feature.","metadata":{}},{"cell_type":"code","source":"# drop the \"image\" feature as it's of no use\nfor df in (train_df, test_df):\n    df.drop(columns=[\"image\"], inplace=True)","metadata":{"execution":{"iopub.status.busy":"2023-09-12T03:52:38.885098Z","iopub.execute_input":"2023-09-12T03:52:38.885456Z","iopub.status.idle":"2023-09-12T03:52:38.902835Z","shell.execute_reply.started":"2023-09-12T03:52:38.885426Z","shell.execute_reply":"2023-09-12T03:52:38.901572Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# types + any missing values?\ntrain_df.info()","metadata":{"execution":{"iopub.status.busy":"2023-09-12T03:52:38.904831Z","iopub.execute_input":"2023-09-12T03:52:38.905333Z","iopub.status.idle":"2023-09-12T03:52:38.929594Z","shell.execute_reply.started":"2023-09-12T03:52:38.905293Z","shell.execute_reply":"2023-09-12T03:52:38.928387Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Price\n\n","metadata":{}},{"cell_type":"code","source":"# weird that it's a string, is there some weird character around?\nfor x in train_df[\"price\"].unique():\n    try:\n        x = float(x)\n    except ValueError as e:\n        print(x,\"---\", str(e))","metadata":{"execution":{"iopub.status.busy":"2023-09-12T03:52:38.931631Z","iopub.execute_input":"2023-09-12T03:52:38.932049Z","iopub.status.idle":"2023-09-12T03:52:38.941610Z","shell.execute_reply.started":"2023-09-12T03:52:38.932012Z","shell.execute_reply":"2023-09-12T03:52:38.940148Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# deleting the commas as they make no difference + converting to float\ntrain_df[\"price\"] = train_df[\"price\"].str.replace(\",\",\"\").astype(float)","metadata":{"execution":{"iopub.status.busy":"2023-09-12T03:52:38.943799Z","iopub.execute_input":"2023-09-12T03:52:38.944436Z","iopub.status.idle":"2023-09-12T03:52:38.954169Z","shell.execute_reply.started":"2023-09-12T03:52:38.944399Z","shell.execute_reply":"2023-09-12T03:52:38.953028Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# general stats for the target variable\ntrain_df[\"price\"].describe()","metadata":{"execution":{"iopub.status.busy":"2023-09-12T03:52:38.955895Z","iopub.execute_input":"2023-09-12T03:52:38.957076Z","iopub.status.idle":"2023-09-12T03:52:38.980736Z","shell.execute_reply.started":"2023-09-12T03:52:38.957035Z","shell.execute_reply":"2023-09-12T03:52:38.979335Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# coarse-grained look -- a box plot\nsns.boxplot(train_df, y=\"price\")\nplt.show()","metadata":{"execution":{"iopub.status.busy":"2023-09-12T03:52:38.985245Z","iopub.execute_input":"2023-09-12T03:52:38.985719Z","iopub.status.idle":"2023-09-12T03:52:39.280297Z","shell.execute_reply.started":"2023-09-12T03:52:38.985678Z","shell.execute_reply":"2023-09-12T03:52:39.279198Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"We can see two things:\n* The data is highly skewed\n* There seem to be *a lot* of values outside the Q1-Q3 range, and even then we have a clear outlier on top.","metadata":{}},{"cell_type":"code","source":"topk(train_df[\"price\"], k=10)","metadata":{"execution":{"iopub.status.busy":"2023-09-12T03:52:39.282211Z","iopub.execute_input":"2023-09-12T03:52:39.283062Z","iopub.status.idle":"2023-09-12T03:52:39.293777Z","shell.execute_reply.started":"2023-09-12T03:52:39.283022Z","shell.execute_reply":"2023-09-12T03:52:39.292144Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"fig, ax = plt.subplots(figsize=(10,8))\n\n# ECDF on log scale\nax = sns.ecdfplot(train_df,x=\"price\",log_scale=True,ax=ax, color=\"blue\")\n\n# we want a finer granularity than default 0.2 -- y ticks every 0.1\nax.set_yticks(np.linspace(0,1,11))\nax.grid()\n\n# show Q1 and Q3\nfor q in (0.25,0.75):\n    ax.axhline(q, xmin=0, xmax=1, linestyle=\"dashed\", color=\"orange\")\n\nplt.show()","metadata":{"execution":{"iopub.status.busy":"2023-09-12T03:52:39.296307Z","iopub.execute_input":"2023-09-12T03:52:39.296966Z","iopub.status.idle":"2023-09-12T03:52:40.443242Z","shell.execute_reply.started":"2023-09-12T03:52:39.296913Z","shell.execute_reply":"2023-09-12T03:52:40.442272Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"1. Almost 40% of the samples cost at most 1 ETH\n2. Over 90% of the samples cost below 100 ETH, the fraction raises to ~99% for 1000 ETH\n3. From the top-k we know all top-5 prices are outliers","metadata":{}},{"cell_type":"markdown","source":"## Speed","metadata":{}},{"cell_type":"code","source":"# how many unique values do we find out of the 2k samples?\ntrain_df[\"speed\"].nunique()","metadata":{"execution":{"iopub.status.busy":"2023-09-12T03:52:40.444813Z","iopub.execute_input":"2023-09-12T03:52:40.445224Z","iopub.status.idle":"2023-09-12T03:52:40.456271Z","shell.execute_reply.started":"2023-09-12T03:52:40.445191Z","shell.execute_reply":"2023-09-12T03:52:40.455307Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# is there any unseen value at test?\nset(test_df[\"speed\"])-set(train_df[\"speed\"])","metadata":{"execution":{"iopub.status.busy":"2023-09-12T03:52:40.458920Z","iopub.execute_input":"2023-09-12T03:52:40.459389Z","iopub.status.idle":"2023-09-12T03:52:40.469286Z","shell.execute_reply.started":"2023-09-12T03:52:40.459346Z","shell.execute_reply":"2023-09-12T03:52:40.468274Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"So only 14 unique values and no new ones at test, we can look at the training set ones and encode such values accordingly!","metadata":{}},{"cell_type":"code","source":"pd.value_counts(train_df[\"speed\"])","metadata":{"execution":{"iopub.status.busy":"2023-09-12T03:52:40.471737Z","iopub.execute_input":"2023-09-12T03:52:40.472040Z","iopub.status.idle":"2023-09-12T03:52:40.482787Z","shell.execute_reply.started":"2023-09-12T03:52:40.472014Z","shell.execute_reply":"2023-09-12T03:52:40.481529Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"This is an inherently (positive) real-valued feature that measures time interval durations. As the shortest one is 1 minute, we can encode it as the number of minutes.","metadata":{}},{"cell_type":"code","source":"# encoding as minutes\ndef encode_speed(speed):\n    # faster than regex\n    cd = speed.split(\"(\")[1].split(\")\")[0]\n    num, unit = int(cd[:-1]), cd[-1]\n    translate={\n        'm': 1,\n        'h': 60,\n        'd': 60*24,\n        'w': 60*24*7\n    }\n    return num * translate[unit]\n\n# test drive\nsample = train_df[\"speed\"][3]\nsample, encode_speed(sample)","metadata":{"execution":{"iopub.status.busy":"2023-09-12T03:52:40.484573Z","iopub.execute_input":"2023-09-12T03:52:40.485027Z","iopub.status.idle":"2023-09-12T03:52:40.495878Z","shell.execute_reply.started":"2023-09-12T03:52:40.484967Z","shell.execute_reply":"2023-09-12T03:52:40.494915Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# apply encoding\nfor df in (train_df, test_df):\n    df[\"speed_encoded\"] = df[\"speed\"].apply(encode_speed)\n    \ntrain_df.head()","metadata":{"execution":{"iopub.status.busy":"2023-09-12T03:52:40.497420Z","iopub.execute_input":"2023-09-12T03:52:40.498284Z","iopub.status.idle":"2023-09-12T03:52:40.521049Z","shell.execute_reply.started":"2023-09-12T03:52:40.498229Z","shell.execute_reply":"2023-09-12T03:52:40.520031Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"But is it a good regressor?","metadata":{}},{"cell_type":"code","source":"# plot\nsns.violinplot(x=train_df[\"speed_encoded\"], y=np.log10(train_df[\"price\"]), log_scale=True)","metadata":{"execution":{"iopub.status.busy":"2023-09-12T03:52:40.522618Z","iopub.execute_input":"2023-09-12T03:52:40.522971Z","iopub.status.idle":"2023-09-12T03:52:41.153412Z","shell.execute_reply.started":"2023-09-12T03:52:40.522925Z","shell.execute_reply":"2023-09-12T03:52:41.152292Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# how well does it correlate with price?\npearson = np.corrcoef(train_df[\"speed_encoded\"],train_df[\"price\"])[0,1]\n\nspearman = stats.spearmanr(train_df[\"speed_encoded\"],train_df[\"price\"])[0]\n\nprint(f\"{pearson=:.3}\\n{spearman=:.3}\")","metadata":{"execution":{"iopub.status.busy":"2023-09-12T03:52:41.155118Z","iopub.execute_input":"2023-09-12T03:52:41.155789Z","iopub.status.idle":"2023-09-12T03:52:41.170624Z","shell.execute_reply.started":"2023-09-12T03:52:41.155752Z","shell.execute_reply":"2023-09-12T03:52:41.169463Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"While it doesn't look like a great predictor in the continuous sense, it seems that some groups are not as sparsely distributed. We can exploit this behavior on a group-wise statistic-based baseline model.","metadata":{}},{"cell_type":"markdown","source":"# Baseline: predicting price using only speed group statistics","metadata":{}},{"cell_type":"code","source":"def MAD(arraylike):\n    return np.median((arraylike - np.median(arraylike)).abs())\n\ndef IQR(arraylike):\n    x = np.quantile(arraylike, (0.25, 0.75))\n    return x[1] - x[0]\n\ndef trimmed_mean(arraylike, p=0.05):\n    lower, upper = np.quantile(arraylike, (p, 1-p))\n    return arraylike[(arraylike >= lower) & (arraylike <= upper)].mean()\n    \n\ndef get_measures(df):\n    res = df.groupby(\"speed_encoded\").agg({\"price\": [len, min,  max, \n                                                     np.median, MAD, IQR, \n                                                     np.mean, np.std, \n                                                     trimmed_mean, \n                                                     lambda x: trimmed_mean(x,0.1)]})\n    # reset column index - not so straightforward\n    res.columns = list(res.columns.get_level_values(1))[:-2]+[f\"trimmed_mean_{p}\" for p in (\"05\",\"1\")]\n    return res\n\ntrain_measures = get_measures(train_df)\ntrain_measures","metadata":{"execution":{"iopub.status.busy":"2023-09-12T03:52:41.172539Z","iopub.execute_input":"2023-09-12T03:52:41.173175Z","iopub.status.idle":"2023-09-12T03:52:41.252670Z","shell.execute_reply.started":"2023-09-12T03:52:41.173134Z","shell.execute_reply":"2023-09-12T03:52:41.251586Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"FOLDS = 5\nsplitter = StratifiedKFold(FOLDS, shuffle=True, random_state=42)\noof_predictions = train_df[[\"speed_encoded\", \"price\"]].copy()\nfeatures = [\"mean\", \"median\", \"IQR\", \"MAD\", \"std\", \"trimmed_mean_05\", \"trimmed_mean_1\"]\nfor feature in features:\n    oof_predictions[feature] = 0\n\npreds = {\n    \"mean\": lambda df: df[\"mean\"],\n    \"median\": lambda df: df[\"median\"],\n    \"tmean_05\": lambda df: df[\"trimmed_mean_05\"],\n    \"tmean_1\": lambda df: df[\"trimmed_mean_1\"],\n    \"median-IQR\": lambda df: df[\"median\"]-df[\"IQR\"]/2,\n    \"median-MAD\": lambda df: df[\"median\"]-df[\"MAD\"],\n    \"tmean_05-MAD\": lambda df: df[\"trimmed_mean_05\"]-df[\"MAD\"],\n    \"tmean_1-MAD\": lambda df: df[\"trimmed_mean_1\"]-df[\"MAD\"],\n}\n\nerrors = {k: np.empty(FOLDS) for k in preds}\n\nfor idx, (train_idxs, test_idxs) in enumerate(splitter.split(train_df, train_df[\"speed_encoded\"])):\n    train = train_df.loc[train_idxs]\n    oof = oof_predictions.loc[test_idxs]\n    \n    measures = get_measures(train)[features]\n    merged = (\n        oof[[\"speed_encoded\"]]\n        .merge(measures,left_on=\"speed_encoded\",right_index=True)\n    )\n    \n    for k, f in preds.items():\n        errors[k][idx] = mean_absolute_error(oof[\"price\"], f(merged))\n    \n    oof_predictions.loc[test_idxs, features] = merged\n    \n    \noof_predictions","metadata":{"execution":{"iopub.status.busy":"2023-09-12T03:52:41.254201Z","iopub.execute_input":"2023-09-12T03:52:41.256336Z","iopub.status.idle":"2023-09-12T03:52:41.545451Z","shell.execute_reply.started":"2023-09-12T03:52:41.256297Z","shell.execute_reply":"2023-09-12T03:52:41.544282Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"results = pd.DataFrame(errors)\nresults","metadata":{"execution":{"iopub.status.busy":"2023-09-12T03:52:41.547076Z","iopub.execute_input":"2023-09-12T03:52:41.547784Z","iopub.status.idle":"2023-09-12T03:52:41.565864Z","shell.execute_reply.started":"2023-09-12T03:52:41.547733Z","shell.execute_reply":"2023-09-12T03:52:41.564634Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"We can easily see that:\n* Per-fold MAE has huge variability, mostly due to mentioned outliers. Even if MAE is a robust metric, with too many orders of magnitude the performance values are still dominated by said extreme samples.\n* Median and 0.1-trimmed mean (and their MAD-discounted variations) strictly outperform all the others.\n\nBecause of its simplicity and its invariability with respect to any work we perform on the more extremed values (e.g. clipping them) we will go for the group-median as a baseline model.","metadata":{}},{"cell_type":"code","source":"# predict with median\nmedian_preds = (\n    test_df[[\"id\",\"speed_encoded\"]]\n    .merge(train_measures[[\"median\"]], left_on=\"speed_encoded\", right_index=True)\n)[\"median\"].to_numpy()","metadata":{"execution":{"iopub.status.busy":"2023-09-12T03:52:41.576353Z","iopub.execute_input":"2023-09-12T03:52:41.576681Z","iopub.status.idle":"2023-09-12T03:52:41.588021Z","shell.execute_reply.started":"2023-09-12T03:52:41.576654Z","shell.execute_reply":"2023-09-12T03:52:41.586843Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"submit(median_preds, \"median\")","metadata":{"execution":{"iopub.status.busy":"2023-09-12T03:52:41.590205Z","iopub.execute_input":"2023-09-12T03:52:41.590631Z","iopub.status.idle":"2023-09-12T03:52:41.600722Z","shell.execute_reply.started":"2023-09-12T03:52:41.590596Z","shell.execute_reply":"2023-09-12T03:52:41.599486Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Clipping the targets\n\nGiven how the more extreme values dominate the MAE we can expect any supervised model that directly minimizes it to suffer from this effect. Two possible ways of dealing with this are clipping the targets and dropping the *toxic* samples.\nAs clipping preserves the size of the dataset and possibly lets us learn \"high-price\" features without forcing the models to only learn to predict those correctly, we will opt for this.","metadata":{}},{"cell_type":"markdown","source":"Thresholds of 100, 500 and 1000 were tried, with 100 maximizing the unclipped-validation-set performance.","metadata":{}},{"cell_type":"code","source":"CLIP_THRESHOLD = 100","metadata":{"execution":{"iopub.status.busy":"2023-09-12T03:52:41.602950Z","iopub.execute_input":"2023-09-12T03:52:41.603402Z","iopub.status.idle":"2023-09-12T03:52:41.609226Z","shell.execute_reply.started":"2023-09-12T03:52:41.603365Z","shell.execute_reply":"2023-09-12T03:52:41.607845Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# keep clipped prices\nclipped_prices = train_df[\"price\"].clip(upper=CLIP_THRESHOLD)","metadata":{"execution":{"iopub.status.busy":"2023-09-12T03:52:41.611202Z","iopub.execute_input":"2023-09-12T03:52:41.611650Z","iopub.status.idle":"2023-09-12T03:52:41.621469Z","shell.execute_reply.started":"2023-09-12T03:52:41.611611Z","shell.execute_reply":"2023-09-12T03:52:41.620352Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Finetuning pretrained Vision models\n\nWe will now finetune models pretrained on ImageNet, which we will modify by changing their last (classifier) layer for a regression one. The full list of models can be found [here](https://pytorch.org/vision/stable/models.html#table-of-all-available-classification-weights).\n\n* [EfficientNet V2 M](https://pytorch.org/vision/stable/models/generated/torchvision.models.efficientnet_v2_m.html#torchvision.models.EfficientNet_V2_M_Weights) and [ResNet50 (V2 weights)](https://pytorch.org/vision/stable/models/generated/torchvision.models.resnet50.html#torchvision.models.ResNet50_Weights) were considered.\n* Three kinds of losses were explored: L1, [SmoothL1](https://pytorch.org/docs/stable/generated/torch.nn.SmoothL1Loss.html) and a custom huber-like Linear-Root one.\n* Two kinds of activations were considered:\n    * Linear: can map all real numbers, has the same gradient for any target value.\n    * [Softplus](https://pytorch.org/docs/stable/generated/torch.nn.Softplus.html): maps only positive numbers (a pro) but may have a harder time learning to predict very small values due to small/vanishing gradients (this is a con).","metadata":{}},{"cell_type":"markdown","source":"## Sanity checks","metadata":{}},{"cell_type":"code","source":"# all ids have their corresponding image path\nno_img = [[\n    img_id for img_id in df[\"id\"]\n    if not (IMG_PATH / (img_id+\".png\")).exists()\n] for df in (train_df, test_df)]\n\nno_img","metadata":{"execution":{"iopub.status.busy":"2023-09-12T03:52:41.623162Z","iopub.execute_input":"2023-09-12T03:52:41.623570Z","iopub.status.idle":"2023-09-12T03:52:48.366924Z","shell.execute_reply.started":"2023-09-12T03:52:41.623533Z","shell.execute_reply":"2023-09-12T03:52:48.365858Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"script false --no-raise-error\n# do all images in the training set have the same size?\nimg_sizes = [cv2.imread(str(IMG_PATH / (img_id+\".png\"))).shape for img_id in train_df[\"id\"]]\nCounter(img_sizes)","metadata":{"execution":{"iopub.status.busy":"2023-09-12T03:52:48.369127Z","iopub.execute_input":"2023-09-12T03:52:48.370030Z","iopub.status.idle":"2023-09-12T03:52:48.386174Z","shell.execute_reply.started":"2023-09-12T03:52:48.369995Z","shell.execute_reply":"2023-09-12T03:52:48.384990Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"* All images are available for all rows in both the training and test set\n* There are multiple sizes for the images, although one accounts for the majority of them. At test time and for the models this is not a problem as they resize as part of their preprocessing pipeline, but larger than 1 batches cannot be constructed for differently sized images. Prior resizing will be needed.","metadata":{}},{"cell_type":"markdown","source":"## Datasets and augmentation transforms\n\nGiven how small the dataset is, we can get away with preemptively loading them in memory, making the training loop faster by removing the I/O bottleneck.","metadata":{}},{"cell_type":"code","source":"class PreLoadedImageDataset(Dataset):\n    def __init__(self, imgs, df=None, targets=None, transforms=None, train=True):\n        assert(df is not None or targets is not None)\n        self.imgs = imgs\n        if train is False:\n            self.target = None\n        else:\n            if df is not None:\n                self.target = df[\"price\"].to_numpy()\n            if targets is not None:\n                self.target = targets\n        self.t = transforms\n    \n    def __len__(self):\n        return len(self.imgs)\n    \n    def __getitem__(self, idx):\n        img = self.imgs[idx]\n        res = (img, self.target[idx]) if self.target is not None else img\n        return self.t(res) if self.t is not None else res","metadata":{"execution":{"iopub.status.busy":"2023-09-12T03:52:48.387645Z","iopub.execute_input":"2023-09-12T03:52:48.387966Z","iopub.status.idle":"2023-09-12T03:52:48.399886Z","shell.execute_reply.started":"2023-09-12T03:52:48.387933Z","shell.execute_reply":"2023-09-12T03:52:48.398815Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"train_imgs = read_all_imgs(train_df[\"id\"])\ntest_imgs = read_all_imgs(test_df[\"id\"])","metadata":{"execution":{"iopub.status.busy":"2023-09-12T03:52:48.401384Z","iopub.execute_input":"2023-09-12T03:52:48.402501Z","iopub.status.idle":"2023-09-12T04:01:55.924779Z","shell.execute_reply.started":"2023-09-12T03:52:48.402463Z","shell.execute_reply":"2023-09-12T04:01:55.923658Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"While data augmentation is always good, we have to pick transforms that do not take information away from the images. As we do not know whether color, shape or size matter and upside-down cats don't make sense, we will only use Random Horizontal Flipping. Even though it's only one transformation, this will efectively double our training set size.","metadata":{}},{"cell_type":"code","source":"def get_transforms(p):\n    return RandomHorizontalFlip(p)","metadata":{"execution":{"iopub.status.busy":"2023-09-12T04:01:55.926389Z","iopub.execute_input":"2023-09-12T04:01:55.927049Z","iopub.status.idle":"2023-09-12T04:01:55.932334Z","shell.execute_reply.started":"2023-09-12T04:01:55.927011Z","shell.execute_reply":"2023-09-12T04:01:55.931230Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# clipped targets + augmentation on train\ntrain_dataset = PreLoadedImageDataset(train_imgs, targets=clipped_prices, transforms=get_transforms(0.5))\n\n# unclipped targets + no augmentation on valid\nvalid_dataset = PreLoadedImageDataset(train_imgs, df=train_df, transforms=None)\n\n# no targets on test\ntest_dataset = PreLoadedImageDataset(test_imgs, df=test_df, transforms=None, train=False)","metadata":{"execution":{"iopub.status.busy":"2023-09-12T04:01:55.933739Z","iopub.execute_input":"2023-09-12T04:01:55.934400Z","iopub.status.idle":"2023-09-12T04:01:55.945688Z","shell.execute_reply.started":"2023-09-12T04:01:55.934360Z","shell.execute_reply":"2023-09-12T04:01:55.944686Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Now we split the training set in train and validation subsets by performing a random train-test split. Considering the test set has 120 samples, we keep only a 20% of the train set for validation, which still means 400 samples.","metadata":{}},{"cell_type":"code","source":"VALID_SZ = 400\nVALID_RNG = 42","metadata":{"execution":{"iopub.status.busy":"2023-09-12T04:01:55.947173Z","iopub.execute_input":"2023-09-12T04:01:55.947797Z","iopub.status.idle":"2023-09-12T04:01:55.956716Z","shell.execute_reply.started":"2023-09-12T04:01:55.947762Z","shell.execute_reply":"2023-09-12T04:01:55.955630Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"g = torch.manual_seed(VALID_RNG)\nidxs = torch.randperm(len(train_df), generator=g).tolist()\n\ntrain_subset = Subset(train_dataset, idxs[:-VALID_SZ])\nvalid_subset = Subset(valid_dataset, idxs[-VALID_SZ:])","metadata":{"execution":{"iopub.status.busy":"2023-09-12T04:01:55.958176Z","iopub.execute_input":"2023-09-12T04:01:55.958483Z","iopub.status.idle":"2023-09-12T04:01:55.979376Z","shell.execute_reply.started":"2023-09-12T04:01:55.958458Z","shell.execute_reply":"2023-09-12T04:01:55.978235Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## DataLoaders\n\nFor a more stable training and faster iterations we pick a rather sizeable batch size. Lower values were explored, with no performance gains.","metadata":{}},{"cell_type":"code","source":"TRAIN_BATCH_SZ = 128\nN_WORKERS = 1","metadata":{"execution":{"iopub.status.busy":"2023-09-12T04:01:55.982885Z","iopub.execute_input":"2023-09-12T04:01:55.983863Z","iopub.status.idle":"2023-09-12T04:01:55.988234Z","shell.execute_reply.started":"2023-09-12T04:01:55.983828Z","shell.execute_reply":"2023-09-12T04:01:55.987102Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"train_dl = DataLoader(\n    train_subset, \n    batch_size=TRAIN_BATCH_SZ, \n    shuffle=True,\n    num_workers=N_WORKERS\n)\n\nvalid_dl = DataLoader(\n    valid_subset, \n    batch_size=1, \n    shuffle=False,\n    num_workers=N_WORKERS\n)\n\ntest_dl = DataLoader(\n    test_dataset,\n    batch_size=1,\n    shuffle=False,\n    num_workers=N_WORKERS\n)\n\nlen(train_dl),len(valid_dl), len(test_dl)","metadata":{"execution":{"iopub.status.busy":"2023-09-12T04:01:55.990000Z","iopub.execute_input":"2023-09-12T04:01:55.990426Z","iopub.status.idle":"2023-09-12T04:01:56.002123Z","shell.execute_reply.started":"2023-09-12T04:01:55.990392Z","shell.execute_reply":"2023-09-12T04:01:56.000893Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Models","metadata":{}},{"cell_type":"code","source":"# base class\nclass BackboneRegressor(nn.Module):\n    def __init__(self, extractor_features, regressor=None, use_sp=True):\n        super().__init__()\n        if regressor is None:\n            regressor = nn.Linear(\n                in_features = extractor_features,\n                out_features = 1\n            )\n        self.preprocessor, self.backbone = self.setup(regressor)\n        self.backbone.to(device)\n        self.sp = nn.Softplus() if use_sp else None\n    \n    def setup(self, regressor):\n        raise NotImplementedError(\"override me!\")\n        \n    def forward(self, x):\n        x = self.preprocessor(x)\n        x = self.backbone(x)\n        return self.sp(x) if self.sp is not None else x  ","metadata":{"execution":{"iopub.status.busy":"2023-09-12T04:01:56.004165Z","iopub.execute_input":"2023-09-12T04:01:56.004619Z","iopub.status.idle":"2023-09-12T04:01:56.016023Z","shell.execute_reply.started":"2023-09-12T04:01:56.004587Z","shell.execute_reply":"2023-09-12T04:01:56.014927Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# EfficientNet\nclass EfficientNetRegressor(BackboneRegressor):\n    def __init__(self, regressor=None, use_sp=True):\n        super().__init__(\n            extractor_features=1280,\n            regressor=regressor, \n            use_sp=use_sp\n        )\n    \n    def setup(self, regressor):\n        w = EfficientNet_V2_M_Weights.DEFAULT\n        bb = efficientnet_v2_m(weights=w)\n        bb.classifier = regressor\n        return w.transforms(), bb\n    \n# ResNet\nclass ResNetRegressor(BackboneRegressor):\n    def __init__(self, regressor=None, use_sp=True):\n        super().__init__(2048,regressor, use_sp)\n    \n    def setup(self, regressor):\n        w = ResNet50_Weights.DEFAULT\n        bb = resnet50(weights=w)\n        bb.fc = regressor\n        return w.transforms(), bb","metadata":{"execution":{"iopub.status.busy":"2023-09-12T04:01:56.017129Z","iopub.execute_input":"2023-09-12T04:01:56.017445Z","iopub.status.idle":"2023-09-12T04:01:56.028223Z","shell.execute_reply.started":"2023-09-12T04:01:56.017413Z","shell.execute_reply":"2023-09-12T04:01:56.027329Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"USE_SOFTPLUS = True\nREGRESSOR = None\nMODEL_CLS = ResNetRegressor","metadata":{"execution":{"iopub.status.busy":"2023-09-12T05:05:10.475795Z","iopub.execute_input":"2023-09-12T05:05:10.476290Z","iopub.status.idle":"2023-09-12T05:05:10.482576Z","shell.execute_reply.started":"2023-09-12T05:05:10.476232Z","shell.execute_reply":"2023-09-12T05:05:10.481491Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"model = MODEL_CLS(use_sp=USE_SOFTPLUS, regressor=REGRESSOR)","metadata":{"execution":{"iopub.status.busy":"2023-09-12T05:05:10.662649Z","iopub.execute_input":"2023-09-12T05:05:10.663049Z","iopub.status.idle":"2023-09-12T05:05:11.213529Z","shell.execute_reply.started":"2023-09-12T05:05:10.663018Z","shell.execute_reply":"2023-09-12T05:05:11.212323Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Optimizer and Scheduler\n","metadata":{}},{"cell_type":"code","source":"params = [p for p in model.parameters() if p.requires_grad]\nlen(params)","metadata":{"execution":{"iopub.status.busy":"2023-09-12T05:05:20.793113Z","iopub.execute_input":"2023-09-12T05:05:20.794069Z","iopub.status.idle":"2023-09-12T05:05:20.802191Z","shell.execute_reply.started":"2023-09-12T05:05:20.794030Z","shell.execute_reply":"2023-09-12T05:05:20.801052Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"LR = 1e-3\nMOMENTUM = 0.9\nW_DECAY = 0.01\nSTEP_SZ = 50\nLR_DECAY = 0.5","metadata":{"execution":{"iopub.status.busy":"2023-09-12T05:05:21.051298Z","iopub.execute_input":"2023-09-12T05:05:21.054925Z","iopub.status.idle":"2023-09-12T05:05:21.060715Z","shell.execute_reply.started":"2023-09-12T05:05:21.054872Z","shell.execute_reply":"2023-09-12T05:05:21.059503Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# previous recipe\n\"\"\"\noptimizer = SGD(\n    params,\n    lr=LR,\n    momentum=MOMENTUM,\n    weight_decay=W_DECAY\n)\n\nscheduler = StepLR(\n    optimizer=optimizer,\n    step_size= STEP_SZ,\n    gamma=LR_DECAY\n)\n\"\"\"","metadata":{"execution":{"iopub.status.busy":"2023-09-12T05:05:22.626273Z","iopub.execute_input":"2023-09-12T05:05:22.626659Z","iopub.status.idle":"2023-09-12T05:05:22.634022Z","shell.execute_reply.started":"2023-09-12T05:05:22.626630Z","shell.execute_reply":"2023-09-12T05:05:22.632652Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# current recipe - a simpler, yet more aggressive one\noptimizer = AdamW(\n    params,\n    lr=LR,\n    weight_decay=W_DECAY\n)\n\nscheduler = None","metadata":{"execution":{"iopub.status.busy":"2023-09-12T05:05:22.830367Z","iopub.execute_input":"2023-09-12T05:05:22.830773Z","iopub.status.idle":"2023-09-12T05:05:22.840656Z","shell.execute_reply.started":"2023-09-12T05:05:22.830742Z","shell.execute_reply":"2023-09-12T05:05:22.839577Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Loss","metadata":{}},{"cell_type":"code","source":"# defining the custom Linear-SQRT loss\nclass RootLoss(nn.Module):\n    def __init__(self):\n        super().__init__()\n    \n    def forward(self, yhat, y):\n        residuals = torch.abs(yhat-y)\n        rooted_res = 2*torch.sqrt(residuals)-1\n        return torch.mean(torch.where(residuals > 1, rooted_res, residuals))","metadata":{"execution":{"iopub.status.busy":"2023-09-12T05:05:25.003028Z","iopub.execute_input":"2023-09-12T05:05:25.004069Z","iopub.status.idle":"2023-09-12T05:05:25.010358Z","shell.execute_reply.started":"2023-09-12T05:05:25.004033Z","shell.execute_reply":"2023-09-12T05:05:25.009209Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# this is how it looks like - linear below 1, sqrt after\nyhat = torch.linspace(start=1e-3,end=5,steps=1000)\nypp = torch.zeros_like(yhat)\nrl = RootLoss()\n\n_ = [rl(yhat[idx],ypp[idx]) for idx in range(len(yhat))]\nplt.plot(yhat, _)","metadata":{"execution":{"iopub.status.busy":"2023-09-12T05:05:25.469179Z","iopub.execute_input":"2023-09-12T05:05:25.469875Z","iopub.status.idle":"2023-09-12T05:05:25.854268Z","shell.execute_reply.started":"2023-09-12T05:05:25.469841Z","shell.execute_reply":"2023-09-12T05:05:25.853204Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"While this loss puts even less importance on larger residuals, it didn't improve performance over SmoothL1Loss.","metadata":{}},{"cell_type":"code","source":"#loss = nn.L1Loss()\n#loss = RootLoss()\nloss = nn.SmoothL1Loss()","metadata":{"execution":{"iopub.status.busy":"2023-09-12T05:05:28.021996Z","iopub.execute_input":"2023-09-12T05:05:28.022454Z","iopub.status.idle":"2023-09-12T05:05:28.030307Z","shell.execute_reply.started":"2023-09-12T05:05:28.022417Z","shell.execute_reply":"2023-09-12T05:05:28.029115Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Training loop","metadata":{}},{"cell_type":"code","source":"N_EPOCHS = 60","metadata":{"execution":{"iopub.status.busy":"2023-09-12T05:05:29.276689Z","iopub.execute_input":"2023-09-12T05:05:29.277712Z","iopub.status.idle":"2023-09-12T05:05:29.283356Z","shell.execute_reply.started":"2023-09-12T05:05:29.277669Z","shell.execute_reply":"2023-09-12T05:05:29.281923Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# suppress pesky UserWarning from antialias value from inside the ResNet preprocessing code\nwarnings.filterwarnings(\"ignore\", category=UserWarning)","metadata":{"execution":{"iopub.status.busy":"2023-09-12T05:05:29.484884Z","iopub.execute_input":"2023-09-12T05:05:29.485701Z","iopub.status.idle":"2023-09-12T05:05:29.492158Z","shell.execute_reply.started":"2023-09-12T05:05:29.485653Z","shell.execute_reply":"2023-09-12T05:05:29.490948Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"preds = {}\nmae_historic = np.empty(N_EPOCHS, dtype=float)\nclipped_mae_historic = np.empty(N_EPOCHS, dtype=float)\nclip_min = 13\nunclip_min = 18\n\nclipped_mae_threshold = 11 # for clipped targets\nvalid_clipped_prices = clipped_prices[idxs[-VALID_SZ:]]\n\nfor epoch in range(N_EPOCHS):\n    # train 1 epoch\n    train_one_epoch(\n        train_dataloader=train_dl,\n        model=model,\n        optimizer=optimizer,\n        scheduler=scheduler,\n        criterion = loss, \n        device=device\n    )\n    # calculate, save and report unclipped and clipped MAE\n    mae, valid_preds = evaluate(model,valid_dl,device)\n    clipped_mae = mean_absolute_error(valid_clipped_prices, valid_preds)\n    \n    mae_historic[epoch] = mae\n    clipped_mae_historic[epoch] = clipped_mae\n    \n    clip_min = min(clip_min, clipped_mae)\n    unclip_min = min(unclip_min, mae)\n    \n    # if it's below a threshold also \n    if clipped_mae < clipped_mae_threshold:\n        preds[epoch] = predict(model, test_dl, device, use_tqdm=False)\n    \n    print(\n        f\"Epoch {epoch+1: >2}/{N_EPOCHS}\",\n        f\"UNCLIPPED MAE: {mae:>.3f}\" + (\" <--\" if unclip_min == mae else \"\\t\"), \n        f\"CLIPPED MAE: {clipped_mae:>.3f}\" + (\" <--\" if clip_min == clipped_mae else \"\\t\"),\n        sep=\"\\t\"\n    )\npreds[N_EPOCHS] = predict(model, test_dl, device)","metadata":{"execution":{"iopub.status.busy":"2023-09-12T05:05:29.676071Z","iopub.execute_input":"2023-09-12T05:05:29.676502Z","iopub.status.idle":"2023-09-12T05:21:15.431166Z","shell.execute_reply.started":"2023-09-12T05:05:29.676468Z","shell.execute_reply":"2023-09-12T05:21:15.429713Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# which ones were saved?\npreds.keys()","metadata":{"execution":{"iopub.status.busy":"2023-09-12T05:23:06.890415Z","iopub.execute_input":"2023-09-12T05:23:06.891613Z","iopub.status.idle":"2023-09-12T05:23:06.900322Z","shell.execute_reply.started":"2023-09-12T05:23:06.891573Z","shell.execute_reply":"2023-09-12T05:23:06.899034Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# extremely inefficient yet numba-compilable\ndef rolling_mean(arraylike, lambda_, exclude_first=0, fill=None):       \n    res = np.copy(arraylike) if fill is None else np.full_like(arraylike, fill)\n    aux = arraylike[exclude_first]\n    for idx, x in enumerate(arraylike[exclude_first:]):\n        aux = aux*lambda_ + x*(1-lambda_)\n        res[idx+exclude_first] = aux\n    return res","metadata":{"execution":{"iopub.status.busy":"2023-09-12T05:23:07.046835Z","iopub.execute_input":"2023-09-12T05:23:07.047508Z","iopub.status.idle":"2023-09-12T05:23:07.054853Z","shell.execute_reply.started":"2023-09-12T05:23:07.047471Z","shell.execute_reply":"2023-09-12T05:23:07.053661Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"fig, axes = plt.subplots(figsize=(8,6), nrows=2, sharex=True)\n\n# plot rolling mean+-std\nfor ax, historic, name in zip(axes, \n                              (mae_historic, clipped_mae_historic), \n                              (\"Unclipped MAE\", \"Clipped MAE\")):\n    lambda_ = 0.8\n    ewma = rolling_mean(historic, lambda_, 1, np.nan)\n    ewmstd = np.sqrt(rolling_mean((historic-ewma)**2,lambda_, 1, 0))\n    ax.fill_between(range(len(historic)),ewma+ewmstd, ewma-ewmstd,color='lightgray')\n    ax.plot(ewma, color='gray')\n\n    min_mae = np.argmin(historic)\n    print(\"Min\",name,\" at\",min_mae)\n    for k in preds.keys():\n        color = 'red' if k==min_mae else 'orange'\n        ax.axvline(k, color=color, linestyle='dashed')\n\n    # plot valid MAE trajectory\n    ax.plot(historic, color='blue')\n    ax.set_ylabel(name)\nplt.show()","metadata":{"execution":{"iopub.status.busy":"2023-09-12T05:23:07.962487Z","iopub.execute_input":"2023-09-12T05:23:07.962856Z","iopub.status.idle":"2023-09-12T05:23:08.831065Z","shell.execute_reply.started":"2023-09-12T05:23:07.962827Z","shell.execute_reply":"2023-09-12T05:23:08.830074Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# selecting the min unclipped MAE model\nselected_idx = 20","metadata":{"execution":{"iopub.status.busy":"2023-09-12T05:24:57.167483Z","iopub.execute_input":"2023-09-12T05:24:57.167867Z","iopub.status.idle":"2023-09-12T05:24:57.172688Z","shell.execute_reply.started":"2023-09-12T05:24:57.167836Z","shell.execute_reply":"2023-09-12T05:24:57.171618Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# generate submission\nsubmit(preds[selected_idx],\"resnet\"+str(selected_idx)+(\"sp\" if USE_SOFTPLUS else \"\"))","metadata":{"execution":{"iopub.status.busy":"2023-09-12T05:24:57.508779Z","iopub.execute_input":"2023-09-12T05:24:57.509182Z","iopub.status.idle":"2023-09-12T05:24:57.520164Z","shell.execute_reply.started":"2023-09-12T05:24:57.509148Z","shell.execute_reply":"2023-09-12T05:24:57.518921Z"},"trusted":true},"execution_count":null,"outputs":[]}],"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}}